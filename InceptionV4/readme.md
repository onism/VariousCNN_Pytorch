# Inception V1


                        X
                        |
                        |
    -------------------------------------------
    |               |           |              |
    |               |           |              |
    conv(1,1)     conv(3,3)    conv(5,5)     max pooling(3,3)
    |______________ |___________|______________|
                        |
                    concat





                        X
                        |
                        |
    -------------------------------------------
    |               |           |              |
    |               |           |              |
    conv(1,1)     conv(1,1)    conv(1,1)     max pooling(3,3)
    |             conv(3,3)    conv(5,5)     conv(1,1)
    |______________ |___________|______________|
                        |
                    concat



 # Inception V2       
 减少特征的表征性瓶颈。直观上来说，当卷积不会大幅度改变输入维度时，神经网络可能会执行地更好。过多地减少维度可能会造成信息的损失，这也称为「表征性瓶颈」。                



                        X
                        |
                        |
    -------------------------------------------
    |               |           |              |
    |               |           |              |
    conv(1,1)     conv(1,1)    conv(1,1)     max pooling(3,3)
    |             conv(3,3)    conv(3,3)     conv(1,1)
    |             conv(3,3)     |              |
    |______________ |___________|______________|
                        |
                    concat

此外，作者将 n*n 的卷积核尺寸分解为 1×n 和 n×1 两个卷积。例如，一个 3×3 的卷积等价于首先执行一个 1×3 的卷积再执行一个 3×1 的卷积。他们还发现这种方法在成本上要比单个 3×3 的卷积降低 33%，                    


# Inception V3

